{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector_counter(text):\n",
    "    word = re.compile(r'[^\\d\\W]+\\b') # word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "def cosine_similarity(content_a, content_b):\n",
    "\n",
    "    vector1 = text_to_vector_counter(content_a)\n",
    "    vector2 = text_to_vector_counter(content_b)\n",
    "\n",
    "    cosine_result = get_cosine(vector1, vector2)\n",
    "    return cosine_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    text=text.lower()\n",
    "    word = re.compile(r'[^\\W]+\\b') # word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VepsÃlÃinen Juho'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x='VepsÃ¤lÃ¤inen, Juho'\n",
    "x=re.sub('[^\\w ]','',x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"VepsÃ¤lÃ¤inen, Juho, Asimuzzaman, Md, Pinku Deb Nath, Farah Hossain, Asif Hossain, and Rashedur M\"\n",
    "y=\"rashedur\"\n",
    "\n",
    "x=re.sub('[^\\w ]','',x)\n",
    "author_list=text_to_vector(x)\n",
    "text_list=text_to_vector(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vepsãlãinen',\n",
       " 'juho',\n",
       " 'asimuzzaman',\n",
       " 'md',\n",
       " 'pinku',\n",
       " 'deb',\n",
       " 'nath',\n",
       " 'farah',\n",
       " 'hossain',\n",
       " 'asif',\n",
       " 'hossain',\n",
       " 'and',\n",
       " 'rashedur',\n",
       " 'm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check =  all(item in author_list for item in text_list)\n",
    "\n",
    "check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir=r'C:\\Users\\Saranga\\Desktop\\Devopedia\\Work\\Devopedia\\csv_outputs_from_HTML3'\n",
    "output_dir=r'C:\\Users\\Saranga\\Desktop\\Devopedia\\Work\\Devopedia\\csv_outputs_encodings3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6761/6761 [12:53<00:00,  8.74it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for _,_,files in os.walk(csv_dir):\n",
    "    for file in tqdm(files):\n",
    "        \n",
    "\n",
    "        fpath=os.path.join(csv_dir,file)\n",
    "        \n",
    "        title_enc=[]\n",
    "        author_enc=[]\n",
    "        yop_enc=[]\n",
    "        \n",
    "        df=pd.read_csv(fpath)\n",
    "        \n",
    "        if df.size==0:\n",
    "            continue\n",
    "        \n",
    "#         temp_author=re.sub('[^\\w ]','',df.Author[0])\n",
    "        author_list=text_to_vector(df.Author[0])\n",
    "\n",
    "        for i in df.iterrows():\n",
    "            \n",
    "            if str(i[1].Title) in str(i[1].Text) or cosine_similarity(str(i[1].Title),str(i[1].Text))>0.97:\n",
    "                title_enc.append(1)\n",
    "            else:\n",
    "                title_enc.append(0)\n",
    "                \n",
    "#                 title_list=text_to_vector(str(i[1].Title))\n",
    "#                 text_list=text_to_vector(str(i[1].Text))\n",
    "\n",
    "#                 check=all(item in text_list for item in title_list)\n",
    "\n",
    "#                 if check:\n",
    "#                     title_enc.append(1)\n",
    "#                 else:\n",
    "#                     title_enc.append(0)\n",
    "                \n",
    "#             if str(i[1].Author) in str(i[1].Text) or textdistance.jaro_winkler(str(i[1].Author),str(i[1].Text))>0.7:\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            text_list=text_to_vector(str(i[1].Text))\n",
    "    \n",
    "            if text_list!=['and']:\n",
    "            \n",
    "                check=all(item in author_list for item in text_list)\n",
    "\n",
    "                if check:\n",
    "                    author_enc.append(1)\n",
    "                else:\n",
    "                    author_enc.append(0)\n",
    "\n",
    "            else:\n",
    "                author_enc.append(0)\n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    "                \n",
    "#             if str(i[1].YoPublishing) in str(i[1].Text):\n",
    "#                 yop_enc.append(1)\n",
    "#             else:\n",
    "#                 yop_enc.append(0)\n",
    "                \n",
    "\n",
    "            yop_list=text_to_vector(str(i[1].YoPublishing))\n",
    "            \n",
    "            check=all(item in yop_list for item in text_list)\n",
    "\n",
    "            if check:\n",
    "                yop_enc.append(1)\n",
    "            else:\n",
    "                yop_enc.append(0)\n",
    "                \n",
    "        if 1 not in author_enc:\n",
    "            \n",
    "            if len(author_list)>1:\n",
    "            \n",
    "                author_enc=[]\n",
    "\n",
    "                for index in df.iterrows():\n",
    "\n",
    "\n",
    "                    text_list=text_to_vector(str(index[1].Text))\n",
    "\n",
    "                    check=all(item in text_list for item in author_list)\n",
    "                    if check:\n",
    "                        author_enc.append(1)\n",
    "                    else:\n",
    "                        author_enc.append(0)\n",
    "            \n",
    "        \n",
    "                \n",
    "        df['Title_encoding']=title_enc\n",
    "        df['Author_encoding']=author_enc\n",
    "        df['YoP_encoding']=yop_enc\n",
    "        \n",
    "        df['SerialNo']=list(range(1,len(title_enc)+1))    #or len(author_enc) or len(yop_encoding)\n",
    "        \n",
    "        \n",
    "        df=df[['YoPublishing','Title','Author','fname','Title_encoding',\n",
    "               'Author_encoding','YoP_encoding','SerialNo','Tag','Text']]\n",
    "\n",
    "    \n",
    "        output_path=os.path.join(output_dir,file)\n",
    "        df.to_csv(output_path,index=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_csv_dir=output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6761/6761 [33:23<00:00,  3.38it/s]\n"
     ]
    }
   ],
   "source": [
    "Author_distinct_count=[]\n",
    "Title_distinct_count=[]\n",
    "fnames=[]\n",
    "Authors=[]\n",
    "Titles=[]\n",
    "error_count=0\n",
    "\n",
    "row_count=0\n",
    "\n",
    "df_all=pd.DataFrame(columns=['YoPublishing','Title','Author','fname','Title_encoding','Author_encoding',\n",
    "                             'YoP_encoding','SerialNo','Tag','Text'])\n",
    "\n",
    "\n",
    "for _,_,files in os.walk(enc_csv_dir):\n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        fpath=os.path.join(enc_csv_dir,file)\n",
    "\n",
    "        df=pd.read_csv(fpath)\n",
    "            \n",
    "        try:\n",
    "            df_all = df_all.append(df, ignore_index = True)\n",
    "\n",
    "            fnames.append(df.fname[0])\n",
    "\n",
    "            Author_distinct_count.append(df[df.Author_encoding==1].Text.nunique())\n",
    "            Authors.append(df.Author[0])\n",
    "            Titles.append(df.Title[0])\n",
    "            Title_distinct_count.append(df[df.Title_encoding==1].Text.nunique())\n",
    "            \n",
    "            row_count+=len(df)\n",
    "            \n",
    "        except:\n",
    "\n",
    "            traceback.print_exc()\n",
    "            error_count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1969471, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_output_path=r'C:\\Users\\Saranga\\Desktop\\Devopedia\\Work\\articleRefs.v2525'\n",
    "\n",
    "all_csv_file_path=os.path.join(master_output_path,'all_full_6.csv')\n",
    "df_all.to_csv(all_csv_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Author_distinct_count_df=pd.DataFrame(list(zip(fnames,Author_distinct_count,Authors)),\n",
    "                                         columns=['Fname','Distinct_authors_count','Authors'])\n",
    "Author_distinct_count_df=Author_distinct_count_df.sort_values(by=['Distinct_authors_count'], ascending=True)\n",
    "\n",
    "Author_output_path=os.path.join(master_output_path,'Author_diagnostics_full_6.csv')\n",
    "Author_distinct_count_df.to_csv(Author_output_path,index=False)\n",
    "\n",
    "\n",
    "Title_distinct_count_df=pd.DataFrame(list(zip(fnames,Title_distinct_count,Titles)),\n",
    "                                         columns=['Fname','Distinct_titles_count','Titles'])\n",
    "Title_distinct_count_df=Title_distinct_count_df.sort_values(by=['Distinct_titles_count'], ascending=True)\n",
    "\n",
    "Title_output_path=os.path.join(master_output_path,'Title_diagnostics_full_6.csv')  \n",
    "Title_distinct_count_df.to_csv(Title_output_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fname</th>\n",
       "      <th>Distinct_authors_count</th>\n",
       "      <th>Authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>975cd5bbfc391a7916cbd6693137107cc9f913a717c4f0...</td>\n",
       "      <td>0</td>\n",
       "      <td>3GPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>ca777f66129d6f2e31d6192c675ce1945b4f95ea5aa548...</td>\n",
       "      <td>0</td>\n",
       "      <td>KeyCDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>35301d2e1ec456d49cef89b294faf029d2feda3506dcc7...</td>\n",
       "      <td>0</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>68deb4b9287e1584a0a85c634c1f6a33318a98de32f5ae...</td>\n",
       "      <td>0</td>\n",
       "      <td>SiFive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>caa07ca710574370dea4aa7f33fa6bdbd4d25aac991cbf...</td>\n",
       "      <td>0</td>\n",
       "      <td>Marketwired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>85aa7560cd4e7ecf119f85190a68f82f710219299c5bd9...</td>\n",
       "      <td>126</td>\n",
       "      <td>Google Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>e5a7ce77bd98df91ab464bbc3dcf5d3d021c4141a7ff1e...</td>\n",
       "      <td>135</td>\n",
       "      <td>Google Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>d9cf605d2c097a7d57426458affc5d89e1a86d7d79b631...</td>\n",
       "      <td>135</td>\n",
       "      <td>Google Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>87fe36fbed0c4447240650a875536c1cd9119530ae2854...</td>\n",
       "      <td>138</td>\n",
       "      <td>Google Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>1fdc84e4256b2698c943ccb344c6ca9d4045c08d3e1e66...</td>\n",
       "      <td>178</td>\n",
       "      <td>Google Cloud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Fname  \\\n",
       "3963  975cd5bbfc391a7916cbd6693137107cc9f913a717c4f0...   \n",
       "5382  ca777f66129d6f2e31d6192c675ce1945b4f95ea5aa548...   \n",
       "1392  35301d2e1ec456d49cef89b294faf029d2feda3506dcc7...   \n",
       "2707  68deb4b9287e1584a0a85c634c1f6a33318a98de32f5ae...   \n",
       "5385  caa07ca710574370dea4aa7f33fa6bdbd4d25aac991cbf...   \n",
       "...                                                 ...   \n",
       "3490  85aa7560cd4e7ecf119f85190a68f82f710219299c5bd9...   \n",
       "6066  e5a7ce77bd98df91ab464bbc3dcf5d3d021c4141a7ff1e...   \n",
       "5789  d9cf605d2c097a7d57426458affc5d89e1a86d7d79b631...   \n",
       "3550  87fe36fbed0c4447240650a875536c1cd9119530ae2854...   \n",
       "792   1fdc84e4256b2698c943ccb344c6ca9d4045c08d3e1e66...   \n",
       "\n",
       "      Distinct_authors_count       Authors  \n",
       "3963                       0          3GPP  \n",
       "5382                       0        KeyCDN  \n",
       "1392                       0     Accenture  \n",
       "2707                       0        SiFive  \n",
       "5385                       0   Marketwired  \n",
       "...                      ...           ...  \n",
       "3490                     126  Google Cloud  \n",
       "6066                     135  Google Cloud  \n",
       "5789                     135  Google Cloud  \n",
       "3550                     138  Google Cloud  \n",
       "792                      178  Google Cloud  \n",
       "\n",
       "[6761 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Author_distinct_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_special_char_check=re.compile('[^a-zA-Z0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x='Z3%al'\n",
    "\n",
    "print(tag_special_char_check.search(x)!=None)#exclude tags having special characters \n",
    "                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
